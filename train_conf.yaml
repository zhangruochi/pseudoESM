model:
  protein_bert_base:
    arch: protein_bert_base
    embed_dim: 768
    layers: 6
    ffn_embed_dim: 3072
    attention_heads: 12
    final_bias: True


train:
  random_seed: 7
  num_epoch: 5
  batch_size: 4
  num_workers: 1
  device_ids: [0]
  warmup_steps: 1
  weight_decay: 0.01
  learning_rate: 5e-5
  adam_epsilon: 1e-8
  gradient_accumulation_steps: 1
  max_grad_norm: 5
  eval_steps: 1

data:
  train_dir: "./data/train"
  valid_dir: "./data/eval"
  test_dir: "./data/test"


logger:
  log: True
  logger_type: "pytorch"
  log_dir: "runs"
  per_n_steps: 10
  num_evidence: 5
  comparison_matric: f1
  final_artifact_path: final
  mlflow:
    AWS_ACCESS_KEY_ID: root
    AWS_SECRET_ACCESS_KEY: rootroot
    MLFLOW_S3_ENDPOINT_URL: http://192.168.1.232:6000
    MLFLOW_TRACKING_URI: http://192.168.1.232:7000
    MLFLOW_EXPERIMENT_NAME: "pseudo_esm"
    REGISTERED_MODEL_NAME: "PSEUDO_ESM"

  std:
    file_path: outputs/std.log

inference:
  model_path: "./inference_models/v9/final/model"

other:
  debug: false
