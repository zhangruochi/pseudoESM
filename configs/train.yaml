mode:
  gpu: true

model:
  protein_bert_base:
    arch: protein_bert_base
    embed_dim: 768
    max_positions: 512
    layers: 6
    ffn_embed_dim: 3072
    attention_heads: 12
    final_bias: True
  task:
    max_length: 512
    mlm: true
    mlm_probability: 0.15

train:
  amp: true
  random_seed: 7
  num_epoch: 10
  batch_size: 8
  num_workers: 2
  warmup_steps_ratio: 0.05
  weight_decay: 0
  learning_rate: 1e-4
  adam_epsilon: 1e-8
  gradient_accumulation_steps: 12
  max_grad_norm: 5
  eval_per_steps: 5000
  pin_memory: False
  device_ids: []

data:
  total_train_num: 2000000
  total_valid_num: 50000
  total_test_num: 50000
  train_dir: "./data/train"
  valid_dir: "./data/eval"
  test_dir: "./data/test"

logger:
  log: True
  log_dir: "outputs"
  log_per_steps: 24
  final_artifact_path: final
  mlflow:
    AWS_ACCESS_KEY_ID: root
    AWS_SECRET_ACCESS_KEY: rootroot
    MLFLOW_S3_ENDPOINT_URL: http://192.168.1.232:6000
    MLFLOW_TRACKING_URI: http://192.168.1.232:7000
    MLFLOW_EXPERIMENT_NAME: "pseudo_esm"
    REGISTERED_MODEL_NAME: "pseudo_esm"


inference:
  test_dir:  "./data/test"
  total_test_num: 50000
  device_ids: [0]
  batch_size: 32
  num_workers: 1
  model_path: "./pretrained_model/model_step_50_f1_0.223"

other:
  debug: False
  debug_step: 5

